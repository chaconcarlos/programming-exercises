Docker
======
* Environments
  - On Mac OS / Windows -> Docker Desktop
  - Linux: Docker engine supported natively.
* Tools
  - Docker Engine
  - Docker Desktop
  - Docker Hub
  - Docker Composer
  - Kubernetes
* A container should focus on only one thing.
* Isolation and separation -> core concepts.

COMMANDS
========
* docker run [IMAGE_NAME] -> will pull the image and run a container with that image.
  -p [LOCAL_PORT:CONTAINER_PORT] -> exposes the container port as the local port indicated.
  -d -> run in detached mode.
  -i -> enables interactive mode. Keeps STDIN open. Usually combined with -t.
  -t -> allocates a pseudo TTY.
  -v [VOLUME_NAME]:[CONTAINER_PATH] -> creates a named volume in the given host path.
  -v [HOST_PATH]:[CONTAINER_PATH] -> creates a bind mount.
  --rm -> automatically remove the container when it finishes or is stopped.
  --name [CONTAINER_NAME] -> adds a name to the container.
* docker container attach [CONTAINER_NAME] -> attachs to a container.
* docker logs [CONTAINER_NAME] -> check the messages logged by a container without attaching.
  -f -> enables follow mode, which will continue to update.
* docker ps -> List of containers that are running.
  -a List all containers, even the ones that are not running.
* docker build [DOCKERFILE_PATH] -> builds a custom image based on a Dockerfile
  -t [name]:[tag] -> assigns a tag to the image.
* docker start [CONTAINER_NAME] -> restarts a container. With this command, the container will run in the background (detached mode).
  -a -> enables attach mode.
  -i -> enables interactive mode. Keeps STDIN open. Usually combined with -t.
  - start vs run: run creates a container. start restarts an already created container.
* docker stop [CONTAINER_NAME] -> stops a container.
* docker rm [CONTAINER_NAME] -> removes a container. Should be stopped before removing.
* docker images -> list images created.
* docker rmi [IMAGE_NAME] (*) -> removes an image. No containers should be using the image.
* docker image prune -> removes all unused images.
* docker image inspect [IMAGE_NAME] -> shows the whole configuration for the image.
* docker tag [OLD_IMAGE_NAME] [NEW_IMAGE_NAME] -> retags an image. When renaming an image, it creates a clone, doesn't rename perse.
* docker cp [SOURCE_PATH][/.] [CONTAINER_NAME]:[CONTAINER_TARGET_PATH] -> copy files to a container.
  - docker cp [CONTAINER_NAME]:[CONTAINER_TARGET_PATH] [SOURCE_PATH] -> copy files from a container.

IMAGES
======
* Usually, we download images and build images based on those.
* An image is read-only once is created.
  - Changes can only be done by rebuilding.
* When rebuilding an image, if there's no changes in the instructions, it will use a cache to rebuild faster.
  - Layer-based architecture.
* docker build [DOCKERFILE_PATH] -> builds a custom image based on a Dockerfile
* Image tags -> name:tag. For example, node:14

SHARING IMAGES
==============
* Two ways:
  - Share Dockerfile: needs everything outside of the image, and build the image.
  - Share the image: just create a container and run. No build required.
* Images can be pushed to:
  - Docker Hub: official image repository.
  - Private registry. Artifactory?
* Share: docker push [HOST]:[IMAGE_NAME]:[TAG]
  - if no tag is given, it sets it as latest.
* Use: docker pull [HOST]:[IMAGE_NAME]
* If no host is given, uses Docker Hub.
* Log to the repository: docker login

VOLUMES
=======
* Volumes: managed by docker. 
  - Anonymous volumes:
    - Only can access through docker volume.
    - Volumes only exists while the container exists.
    - If new containers are created, an new anonymous volume is created.
    - To clear them: docker volume rm VOL_NAME or docker volume prune
  - Named volumes
    - Exists after the container is stopped / removed.
* Volumes are great for data that should be persistent but doesn't need to be edited.
* By default, they are read/write.
* By adding to the name :ro, will be read-only.
  [HOST_PATH]:[CONTAINER_PATH]:ro
  - Could be good idea with volumes that host code, for example.
* If there are particular subdirectories that need writing permission on a read-only volume, it's possible
  to create a volume for those sub-paths.
* Anonymous volumes
  - Removed after --rm the container.
  - Because it is hosted on the host machine, it can be use for performance improvements.
    - For example, node_modules, /tmp, etc.
  - Cannot be used to share data.
* Named volumes
  - Not tied to a container.
  - Survives container removal.
  - Can be used to share data.
  - Can be reused for the same container.
  - You don't know where they are stored, like anonymous volumes.
* Bind mounts
  - Managed by the user.
  - User defines the folder / path on the host machine.
  - Ideal for persistent and editable data.
  - Is not done from the Dockerfile. 
  - The folders should be registered as resources on Docker to be acccessible.
  - To clear a data of a bind mount, has to be deleted from the host machine.
  - Shared across containers.
  - Can be reused for same container across restarts.
* docker volume inspect [VOLUME_NAME]
  - See all details about a volume.
* In production, you never use a bind mount for the code, so you use copy in the dockerfile for it.
  - In development, the COPY can stay in the Dockerfile, but the bind mount should be created with [HOST_PATH]:[CONTAINER_PATH]:no-copy

.dockerignore FILES
==================
* Restrict what gets copied.
* Works like a .gitignore.
* Good idea to add for example:
  - node_modules (in case of a nodejs app).
  - Git files.
  - Dockerfile.

NODEJS APPS
===========
* Create a bind for the code
* Create an anonymous volume for the node_modules. Yarn 4?
* Monitor changes -> nodemon, devDependency. Use this instead of node to start the app. Not sure how it works with electron.
  - nodemon --watch . --exec "electron ."

ARGUMENTS & ENVIRONMENT VARIABLES
=================================
* ARG
  - Available inside of Dockerfile, not accessible in CMD or any application code.
  - Works like a variable for the scope of the Dockerfile only.
  - Set on image build (docker build) using --build-arg.
* ENV
  - Available inside of Dockerfile and in application code.
  - Set via ENV [NAME] [VALUE] in Dockerfile or via --env on docker run.
  - The ENV can be used in commands in the Dockerfile. For example:
    ENV PORT 80
    EXPOSE $PORT
  - Can be declared in a .env file.
    .env
      PORT=8000
* Don't expose secure data directly in the Dockerfile. This can be set on docker run, or using a .env file.
* Values "baked" in the image can be read using docker history [IMAGE_NAME].

NETWORKING
==========
* Out of the box, containers can send HTTP request to internet.
* To connect to the host, the domain "host.docker.internal" has to be used instead of localhost.
* To connect to other container:
  - docker container inspect will show the IP address to the container -> NOT IDEAL, of course.
  - Creating a network:
    - docker network create [NETWORK_NAME]. Networks can be inspected using docker network ls.
    - By adding --network [NETWORK_NAME] to the docker run command, docker can resolve the containers names when used as URLs: [CONTAINER_NAME]:[PORT]/[PATH]
    - Make sure containers are part of the network.
* Networks can be created using a driver. By default is "bridge". Other options are:
  - host: For standalone containers, isolation between container and host system is removed (i.e. they share localhost as a network)
  - overlay: Multiple Docker daemons (i.e. Docker running on different machines) are able to connect with each other. Only works in "Swarm" mode which is a dated / almost deprecated way of connecting multiple containers
  - macvlan: You can set a custom MAC address to a container - this address can then be used for communication with that container
  - none: All networking is disabled.
  - Third-party plugins: You can install third-party plugins which then may add all kinds of behaviors and functionalities






